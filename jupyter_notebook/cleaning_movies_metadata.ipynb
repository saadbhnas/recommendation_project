{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff72b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "pd.options.display.max_columns=40\n",
    "from sklearn.base import TransformerMixin , BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b72a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\saadb\\Desktop\\dev\\recommendation_project\\jupyter_notebook\\datasets\\movies_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b69d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45400 entries, 0 to 45399\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   adult                  45400 non-null  object \n",
      " 1   belongs_to_collection  3168 non-null   object \n",
      " 2   budget                 8888 non-null   float64\n",
      " 3   genres                 45400 non-null  object \n",
      " 4   id                     45400 non-null  object \n",
      " 5   original_language      45386 non-null  object \n",
      " 6   original_title         45400 non-null  object \n",
      " 7   overview               44453 non-null  object \n",
      " 8   popularity             45394 non-null  float64\n",
      " 9   production_companies   44910 non-null  object \n",
      " 10  production_countries   45389 non-null  object \n",
      " 11  release_date           45336 non-null  object \n",
      " 12  revenue                7408 non-null   float64\n",
      " 13  runtime                43603 non-null  float64\n",
      " 14  spoken_languages       45400 non-null  object \n",
      " 15  status                 45314 non-null  object \n",
      " 16  tagline                20406 non-null  object \n",
      " 17  title                  45394 non-null  object \n",
      " 18  video                  45394 non-null  object \n",
      " 19  vote_average           45394 non-null  float64\n",
      " 20  vote_count             45394 non-null  float64\n",
      "dtypes: float64(6), object(15)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2173bd70",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\saadb\\\\recommendation_project\\\\recommendation_model\\\\dataset\\\\movies_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msaadb\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mrecommendation_project\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mrecommendation_model\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmovies_metadata.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelease_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    572\u001b[0m     dialect,\n\u001b[0;32m    573\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    583\u001b[0m )\n\u001b[0;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\saadb\\\\recommendation_project\\\\recommendation_model\\\\dataset\\\\movies_metadata.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\saadb\\recommendation_project\\recommendation_model\\dataset\\movies_metadata.csv',low_memory=False,date_parser='release_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d589905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d6715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618f4e7",
   "metadata": {},
   "source": [
    "initial thoughts about data :-\n",
    "-irrelevant columns ( id - imdb_id - homepage - poster_path ) id maybe useable if needed to merge data \n",
    "-columns ( belongs_to_collection - tagline ) have a lot of missing data inspect to see what is the reason and how to deal with it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping irrelevant columns \n",
    "data.drop(['imdb_id','homepage','poster_path'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d804821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nothing suspicious about belongs to collection having so much nans \n",
    "data[data['belongs_to_collection'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ab662",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(data['belongs_to_collection'][0].replace(\"'\",'\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd72045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle json data replacing \"\" and '' as json format should be and then use json.loads and if anything went \n",
    "#wrong or some addidtion error like i have visuilized values like nan instead of json dict we replace those with np.nan\n",
    "def handle_json(x):\n",
    "    try :\n",
    "        \n",
    "        x = x.replace(\"'\",'\"')\n",
    "    \n",
    "        x = json.loads(x)\n",
    "        \n",
    "    except :\n",
    "        return np.nan\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply handle_json to 'belongs_to_collection' \n",
    "data['belongs_to_collection'] = data['belongs_to_collection'].apply(lambda x : handle_json(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#action may improve performance \n",
    "#notice that number of nan values increased i was expecting that number of nans will be equal to the number showen above from  \n",
    "# info function after printing number of nan of all columns this number increased by 1323 need to investigate more in this \n",
    "data['belongs_to_collection'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6dcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting collection name from 'belongs_to_collection' as the useful information about this feature \n",
    "data['belongs_to_collection'].apply(lambda x : x['name'] if isinstance(x,dict) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40574480",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['belongs_to_collection'] = data['belongs_to_collection'].apply(lambda x : x['name'] if isinstance(x,dict) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for genres we need to extract all possible genres from multiple dict same concept to deal with json format but to get the \n",
    "# useful final form of the feature will need to modify code used for extraction \n",
    "data['genres'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8470a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealng with json format \n",
    "data['genres'] = data['genres'].apply(lambda x : handle_json(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3719b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used code from course on udemy for the join idea \n",
    "data['genres'].apply(lambda x : '|'.join(i['name'] for i in x) if isinstance(x,list) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genres'] = data['genres'].apply(lambda x : '|'.join(i['name'] for i in x) if isinstance(x,list) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for language column numbers are being counted as language and i think this is not valid \n",
    "data['original_language'].value_counts().tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40028404",
   "metadata": {},
   "source": [
    "# so they are string i think to get the numbers we can use nltk and use that to eliminate number like string or we can iterte \n",
    "# over every row in language column and chech if it contain number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e797e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "for ele in data['original_language'].dropna():\n",
    "    results = re.findall('[0-9]+',ele)\n",
    "    if results:\n",
    "        x.append(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so after extracting numbers that was parsed as strings using re we can remove them but they are represented in float format \n",
    "# and we captured integer format thats why '.0' is added to them \n",
    "for i in x:\n",
    "    i = i + '.0'\n",
    "    data['original_language'].replace(i,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i need to see the duplicate if they are movies remake\n",
    "data['original_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incpecting hamlet for example\n",
    "hamlet = data[(data['original_title']=='Hamlet')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a22cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we see they are the same tilte but different movies so movie remade \n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee86f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i can replace 'No overview found' , 'No Overview' , 'No movie overview available' and blancks with 'missing'\n",
    "data['overview'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d66bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_to_replace_overview = ['No overview found.' , 'No Overview' , 'No movie overview available', ' ','No movie overview available.']\n",
    "for ele in strings_to_replace_overview:\n",
    "    data['overview'].replace(ele,'missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overview'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78037355",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['popularity'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62926668",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['popularity'].replace('Beware Of Frost Bites',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_popularity_no_floats = [x for x in data['popularity'] if not isinstance(x,float)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d015d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_popularity = [x for x in string_popularity_no_floats if re.search('[a-zA-Z]', x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a7a46",
   "metadata": {},
   "source": [
    "after reviwing popularity values noticed that we have 66 movie with 0.0 popularity and this seem odd somehow tried to view those movies but couldnt becuase the numbers are strings and cant convert them to floats becuase we have string also 'Beware Of Frost Bites' i captured by regular expressions so i need to remove or replace 'Beware Of Frost Bites' by nan and convert popularity type to float and inspect the odd popularities so after inspecting the 0.0 popularity thier is relationship i think between missing values in most of columns and the 0.0 popularity we can maybe remove or drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['popularity'] = data['popularity'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_zero_popularity = data[(data['popularity']==0.0)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be575fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index_of_zero_popularity , axis=0 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_zero_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ac58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 'production_companies' column i only need name so i can try extract that \n",
    "data['production_companies'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here missing values represented by empty list []\n",
    "data['production_companies'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f662ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_companies'] = data['production_companies'].apply(lambda x : handle_json(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1250eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_companies'][1][0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0927f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_companies'] = data['production_companies'].apply(lambda x : '|'.join(i['name'] for i in x) if isinstance(x,list) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae09b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_countries'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a783891",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_countries'] = data['production_countries'].apply(lambda x : handle_json(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_countries'] = data['production_countries'].apply(lambda x : '|'.join(i['name'] for i in x) if isinstance(x,list) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f703916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values represented here by empty space we need to replace that with 'missing' \n",
    "data['production_countries'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_countries'].replace('' , 'missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for budget column we have a lot of values with 0 budget and this is not true or vlad value so we can replace these values with \n",
    "#np.nan\n",
    "data['budget'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thier is not a lot of missing values crossponding to 0 budget so we can just replace them with np.nan\n",
    "data[(data['budget']=='0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cupturing strings in budget column\n",
    "string_budget = [x for x in data['budget'] if re.search('[a-zA-Z]', x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b98c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in string_budget:\n",
    "    data['budget'].replace(i,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['budget'] = data['budget'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['budget'].replace(0.0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_date'] = pd.to_datetime(data['release_date'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_date'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruffly same 0.0 as 'budget' for 'revenue' column as we dont know budget we cant know revenue i guess i will replace 0.0 with np.nan too\n",
    "data['revenue'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revenue'].replace(0.0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afde270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime for 1558 is 0.0 and this is not valid also so i will replace these with np.nan also \n",
    "data['runtime'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['runtime'].replace(0.0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spoken_languages'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spoken_languages'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spoken_languages'] = data['spoken_languages'].apply(lambda x : handle_json(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445958dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spoken_languages'] = data['spoken_languages'].apply(lambda x : '|'.join(i['name'] for i in x) if isinstance(x,list) else 'missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['status'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1380333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tagline i can replace - and blancks with missing \n",
    "data['tagline'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagline_replace = ['-' , '']\n",
    "for i in tagline_replace:\n",
    "    data['tagline'].replace(i,'missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e004ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['video'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244772be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote average for 2998 0.0 !!\n",
    "data['vote_average'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note 'genres' , 'production_companies' and 'spoken_languages' have blancks deal with this \n",
    "data[(data['vote_average']==0.0)].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['production_companies'].replace('','missing',inplace=True)\n",
    "data['genres'].replace('','missing',inplace=True)\n",
    "data['spoken_languages'].replace('','missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f408d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#both vote average and vote count 0 to the same rows obersvations \n",
    "data.groupby(['vote_average'])['vote_count'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04429a9d",
   "metadata": {},
   "source": [
    "inspect why vote average of these movies 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d748f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vote_count'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae44150",
   "metadata": {},
   "source": [
    "inspect why some movies have vote count 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['budget'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4282a1",
   "metadata": {},
   "source": [
    "scale revenue and budget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['budget'] = data['budget']/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e672ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revenue'] = data['revenue']/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\saadb\\recommendation_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8df260",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(path_or_buf='jupyter_notebook/datasets/movies_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b069cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a190294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jupyter_notebook/datasets/movies_cleaned.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a95a0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
